# -*- coding: utf-8 -*-
"""Randomforest1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iRjIfDUP4WS2BMglmpmUjeszcKiCLh9M
"""

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import accuracy_score

df = pd.read_csv('heart.csv')

df.head()

df.shape

x = df.iloc[:,0:-1]
y = df.iloc[:,-1]

X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)

X_train.shape

rf = RandomForestClassifier()
rf.fit(X_train,y_train)

y_pred = rf.predict(X_test)

accuracy_score(y_test,y_pred)

"""So performance of random forest algorithm is always better than many other algorithm without tuning

Doing HyperParameter Tuning Using GridSearchCV
"""

#Number of trees in RF

n_estimator =[20,40,60,80,100]

#Number of freatures to consider
max_freatures = [0.2,0.6,1.0]

#Maximum number of levels in tree
max_depth = [3,5,10,None]

#Number of samples
max_samples = [0.5,0.75,1.0]

#creating the dictionary of parameter
para_grid = {'n_estimators':n_estimator,
             'max_features':max_freatures,
             'max_depth':max_depth,
             'max_samples':max_samples}

rf_tuning = RandomForestClassifier()

from sklearn.model_selection import GridSearchCV
rf_grid = GridSearchCV(estimator=rf_tuning,
                       param_grid=para_grid,
                       cv=5,# every random forest will be tarined 5 times
                       verbose=2,
                       n_jobs=-1)

rf_grid.fit(X_train,y_train)

rf_grid.best_params_

rf_grid.best_score_

"""is data is to much than randomsearchcv can be used as it is faster

"""

